import cv2
import threading
import numpy as np
from ultralytics import YOLO
import time
import torch

# ==== C·∫§U H√åNH ====
RTSP_URLS = [
    "rtsp://admin:CYXJBA@192.168.0.109/ch1/main",
    "rtsp://admin:EIUSAY@192.168.0.105/ch1/main",
    "rtsp://admin:DTAJVP@192.168.0.102/ch1/main",
    "rtsp://admin:PBPBND@192.168.0.100/ch1/main",
"rtsp://admin:TIJEQB@192.168.0.111/ch1/main",
"rtsp://admin:PSQSFP@192.168.0.107/ch1/main",


]

NUM_ROWS, NUM_COLS = 2, 3
FRAME_W, FRAME_H = 640, 480
SHOW_RESULT = True
SAVE_OUTPUT = False  # B·∫≠t n·∫øu mu·ªën ghi video

# ==== LOAD YOLOv8 POSE MODEL ====
device = "cuda" if torch.cuda.is_available() else "cpu"
model = YOLO("yolov8n-pose.pt").to(device)
print("‚úÖ Thi·∫øt b·ªã ƒëang s·ª≠ d·ª•ng:", model.device)

# ==== GStreamer pipeline ====
def gstreamer_pipeline(rtsp_url, width, height):
    return (
        f'rtspsrc location={rtsp_url} latency=0 ! '
        'rtph265depay ! h265parse ! nvv4l2decoder ! '
        f'nvvidconv ! video/x-raw, width={width}, height={height}, format=BGRx ! '
        'videoconvert ! video/x-raw, format=BGR ! '
        'appsink drop=1'
    )

# ==== CAMERA THREAD ====
class CameraStream(threading.Thread):
    def __init__(self, rtsp_url):
        super().__init__()
        self.pipeline = gstreamer_pipeline(rtsp_url, FRAME_W, FRAME_H)
        self.cap = cv2.VideoCapture(self.pipeline, cv2.CAP_GSTREAMER)
        self.frame = np.zeros((FRAME_H, FRAME_W, 3), dtype=np.uint8)
        self.lock = threading.Lock()
        self.running = True

    def run(self):
        while self.running:
            ret, frame = self.cap.read()
            if ret:
                with self.lock:
                    self.frame = frame.copy()

    def get_frame(self):
        with self.lock:
            return self.frame.copy()

    def stop(self):
        self.running = False
        self.cap.release()

# ==== KH·ªûI T·∫†O CAMERA STREAMS ====
streams = [CameraStream(url) for url in RTSP_URLS]
for s in streams:
    s.start()

# ==== VIDEO WRITER (tu·ª≥ ch·ªçn) ====
if SAVE_OUTPUT:
    out = cv2.VideoWriter("output_pose.mp4", cv2.VideoWriter_fourcc(*'mp4v'), 20,
                          (FRAME_W * NUM_COLS, FRAME_H * NUM_ROWS))

# ==== V√íNG L·∫∂P CH√çNH ====
prev_time = time.time()

try:
    while True:
        # ==== GH√âP FRAME T·ª™ C√ÅC CAMERA ====
        frames = [s.get_frame() for s in streams]
        grid_rows = [np.hstack(frames[i*NUM_COLS:(i+1)*NUM_COLS]) for i in range(NUM_ROWS)]
        grid_frame = np.vstack(grid_rows)

        # ==== CHUY·ªÇN FRAME SANG TENSOR TR∆Ø·ªöC KHI ƒê∆ØA V√ÄO GPU ====
        # (Ultralytics t·ª± x·ª≠ l√Ω b√™n trong, nh∆∞ng b·∫°n c√≥ th·ªÉ √©p ch·∫Øc ch·∫Øn n·∫øu c·∫ßn)
        # N·∫øu b·∫°n c·∫ßn √©p bu·ªôc, c√≥ th·ªÉ d√πng: model(torch.from_numpy(grid_frame).permute(2,0,1).unsqueeze(0).to(device))

        # ==== YOLO POSE INFERENCE ====
        results = model(grid_frame, imgsz=640, conf=0.5, verbose=False)[0]
        annotated = results.plot()

        # ==== T√çNH FPS ====
        curr_time = time.time()
        fps = 1.0 / (curr_time - prev_time)
        prev_time = curr_time

        # ==== V·∫º FPS ====
        cv2.putText(annotated, f"FPS: {fps:.2f}", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # ==== HI·ªÇN TH·ªä ====
        if SHOW_RESULT:
            cv2.imshow("YOLOv8-Pose - Grid View", annotated)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        # ==== GHI VIDEO ====
        if SAVE_OUTPUT:
            out.write(annotated)

except KeyboardInterrupt:
    print("üõë D·ª´ng ch∆∞∆°ng tr√¨nh b·∫±ng KeyboardInterrupt.")

# ==== D·ªåN D·∫∏P ====
for s in streams:
    s.stop()
if SAVE_OUTPUT:
    out.release()
cv2.destroyAllWindows()

