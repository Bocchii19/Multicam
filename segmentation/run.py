import cv2
import threading
import numpy as np
from ultralytics import YOLO
import time
import torch

# ==== C·∫§U H√åNH ====
RTSP_URLS = [
"rtsp://admin:YDVFNP@192.168.0.108:554/ch1/main",
"rtsp://admin:PBPBND@192.168.0.119:554/ch1/main",
"rtsp://admin:IFPREC@192.168.0.101:554/ch1/main",
"rtsp://admin:KAETPH@192.168.0.110:554/ch1/main",

]

NUM_ROWS, NUM_COLS = 2, 2
FRAME_W, FRAME_H = 640, 480
SHOW_RESULT = True
SAVE_OUTPUT = False  # B·∫≠t n·∫øu mu·ªën ghi video
FLIP_MODE = 0  # 0 = l·∫≠t d·ªçc, 1 = l·∫≠t ngang, -1 = l·∫≠t c·∫£ 2

# ==== LOAD YOLOv8 SEG MODEL ====
device = "cuda" if torch.cuda.is_available() else "cpu"
model = YOLO("yolov8n-seg.pt").to(device)
print("‚úÖ Thi·∫øt b·ªã ƒëang s·ª≠ d·ª•ng:", model.device)

# ==== GStreamer pipeline ====
def gstreamer_pipeline(rtsp_url, width, height):
    return (
        f'rtspsrc location={rtsp_url} latency=0 ! '
        'rtph265depay ! h265parse ! nvv4l2decoder ! '
        f'nvvidconv ! video/x-raw, width={width}, height={height}, format=BGRx ! '
        'videoconvert ! video/x-raw, format=BGR ! '
        'appsink drop=1'
    )

# ==== CAMERA THREAD ====
class CameraStream(threading.Thread):
    def __init__(self, rtsp_url):
        super().__init__()
        self.rtsp_url = rtsp_url
        self.pipeline = gstreamer_pipeline(rtsp_url, FRAME_W, FRAME_H)
        self.cap = cv2.VideoCapture(self.pipeline, cv2.CAP_GSTREAMER)
        self.frame = np.zeros((FRAME_H, FRAME_W, 3), dtype=np.uint8)
        self.lock = threading.Lock()
        self.running = True

    def reconnect(self):
        print(f"üîÑ Reconnecting to {self.rtsp_url} ...")
        self.cap.release()
        time.sleep(1)  # ngh·ªâ m·ªôt ch√∫t tr∆∞·ªõc khi k·∫øt n·ªëi l·∫°i
        self.pipeline = gstreamer_pipeline(self.rtsp_url, FRAME_W, FRAME_H)
        self.cap = cv2.VideoCapture(self.pipeline, cv2.CAP_GSTREAMER)

    def run(self):
        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                print(f"‚ö†Ô∏è M·∫•t k·∫øt n·ªëi {self.rtsp_url}")
                self.reconnect()
                continue

            frame = cv2.flip(frame, FLIP_MODE)
            with self.lock:
                self.frame = frame.copy()

    def get_frame(self):
        with self.lock:
            return self.frame.copy()

    def stop(self):
        self.running = False
        self.cap.release()
        
# ==== KH·ªûI T·∫†O CAMERA STREAMS ====
streams = [CameraStream(url) for url in RTSP_URLS]
for s in streams:
    s.start()

# ==== VIDEO WRITER (tu·ª≥ ch·ªçn) ====
if SAVE_OUTPUT:
    out = cv2.VideoWriter("output_pose.mp4", cv2.VideoWriter_fourcc(*'mp4v'), 20,
                          (FRAME_W * NUM_COLS, FRAME_H * NUM_ROWS))

# ==== V√íNG L·∫∂P CH√çNH ====
prev_time = time.time()

try:
    while True:
        # ==== GH√âP FRAME T·ª™ C√ÅC CAMERA ====
        frames = [s.get_frame() for s in streams]
        grid_rows = [np.hstack(frames[i*NUM_COLS:(i+1)*NUM_COLS]) for i in range(NUM_ROWS)]
        grid_frame = np.vstack(grid_rows)

        # ==== YOLO SEGMENTATION INFERENCE ====
        results = model(grid_frame, imgsz=640, conf=0.5, verbose=False)[0]
        annotated = results.plot()

        # ==== T√çNH FPS ====
        curr_time = time.time()
        fps = 1.0 / (curr_time - prev_time)
        prev_time = curr_time

        # ==== V·∫º FPS ====
        cv2.putText(annotated, f"FPS: {fps:.2f}", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # ==== HI·ªÇN TH·ªä ====
        if SHOW_RESULT:
            cv2.imshow("YOLOv8-Seg - Grid View", annotated)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        # ==== GHI VIDEO ====
        if SAVE_OUTPUT:
            out.write(annotated)

except KeyboardInterrupt:
    print("üõë D·ª´ng ch∆∞∆°ng tr√¨nh b·∫±ng KeyboardInterrupt.")

# ==== D·ªåN D·∫∏P ====
for s in streams:
    s.stop()
if SAVE_OUTPUT:
    out.release()
cv2.destroyAllWindows()

